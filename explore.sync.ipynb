{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7c044e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from transformers import (\n",
    "    GenerationConfig,\n",
    ")\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from fancy_einsum import einsum\n",
    "import einops\n",
    "\n",
    "from record_utils import record_activations, get_module\n",
    "from hook_utils import HookWithCountThreshold\n",
    "from explore_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fb517c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cos = F.cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f983ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config = {\n",
    "    \"data_path\": \"data/train.parquet\",\n",
    "    \"model_path\": \"checkpoints/TinyZero/v4/actor/global_step_300\",\n",
    "    \"probe_path\": \"probe_checkpoints/v2/probe.pt\",\n",
    "    \"batch_size\": 64,\n",
    "    \"valid_size\": 256,\n",
    "    \"max_prompt_length\": 256,\n",
    "    \"max_response_length\": 300,\n",
    "    \"n_layers\": 36,\n",
    "    \"d_model\": 2048,\n",
    "    \"seed\": 42,\n",
    "    \"hook_config\": {\n",
    "        \"hook_layers\": list(range(24, 33)),\n",
    "        \"hook_target_char\": \" (\",\n",
    "        \"hook_target_threshold\": 0,\n",
    "        \"hook_scale\": 20,\n",
    "    },\n",
    "}\n",
    "\n",
    "seed_all(config[\"seed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c21435fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0952ded235a42b49a3cf658e50e43fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "actor = load_model(config[\"model_path\"])\n",
    "generation_config = GenerationConfig(do_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "15163ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original dataset len: 327680\n",
      "filter dataset len: 327680\n"
     ]
    }
   ],
   "source": [
    "\n",
    "_, valid_dataloader = get_dataloader(\n",
    "    config[\"data_path\"],\n",
    "    config[\"batch_size\"],\n",
    "    config[\"max_prompt_length\"],\n",
    "    config[\"valid_size\"],\n",
    "    actor.tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0440cab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2352752/980249850.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  probe_model = torch.load(config[\"probe_path\"]).detach().cuda()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([36, 2048, 2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "probe_model = torch.load(config[\"probe_path\"]).detach().cuda()\n",
    "probe_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e6d02e5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0\n",
      "tensor(-0.9812, device='cuda:0')\n",
      "Layer 1\n",
      "tensor(-0.9841, device='cuda:0')\n",
      "Layer 2\n",
      "tensor(-0.9874, device='cuda:0')\n",
      "Layer 3\n",
      "tensor(-0.9926, device='cuda:0')\n",
      "Layer 4\n",
      "tensor(-0.9930, device='cuda:0')\n",
      "Layer 5\n",
      "tensor(-0.9941, device='cuda:0')\n",
      "Layer 6\n",
      "tensor(-0.9937, device='cuda:0')\n",
      "Layer 7\n",
      "tensor(-0.9935, device='cuda:0')\n",
      "Layer 8\n",
      "tensor(-0.9939, device='cuda:0')\n",
      "Layer 9\n",
      "tensor(-0.9932, device='cuda:0')\n",
      "Layer 10\n",
      "tensor(-0.9938, device='cuda:0')\n",
      "Layer 11\n",
      "tensor(-0.9935, device='cuda:0')\n",
      "Layer 12\n",
      "tensor(-0.9932, device='cuda:0')\n",
      "Layer 13\n",
      "tensor(-0.9938, device='cuda:0')\n",
      "Layer 14\n",
      "tensor(-0.9936, device='cuda:0')\n",
      "Layer 15\n",
      "tensor(-0.9939, device='cuda:0')\n",
      "Layer 16\n",
      "tensor(-0.9939, device='cuda:0')\n",
      "Layer 17\n",
      "tensor(-0.9940, device='cuda:0')\n",
      "Layer 18\n",
      "tensor(-0.9944, device='cuda:0')\n",
      "Layer 19\n",
      "tensor(-0.9940, device='cuda:0')\n",
      "Layer 20\n",
      "tensor(-0.9944, device='cuda:0')\n",
      "Layer 21\n",
      "tensor(-0.9942, device='cuda:0')\n",
      "Layer 22\n",
      "tensor(-0.9946, device='cuda:0')\n",
      "Layer 23\n",
      "tensor(-0.9942, device='cuda:0')\n",
      "Layer 24\n",
      "tensor(-0.9944, device='cuda:0')\n",
      "Layer 25\n",
      "tensor(-0.9941, device='cuda:0')\n",
      "Layer 26\n",
      "tensor(-0.9944, device='cuda:0')\n",
      "Layer 27\n",
      "tensor(-0.9940, device='cuda:0')\n",
      "Layer 28\n",
      "tensor(-0.9939, device='cuda:0')\n",
      "Layer 29\n",
      "tensor(-0.9941, device='cuda:0')\n",
      "Layer 30\n",
      "tensor(-0.9941, device='cuda:0')\n",
      "Layer 31\n",
      "tensor(-0.9941, device='cuda:0')\n",
      "Layer 32\n",
      "tensor(-0.9942, device='cuda:0')\n",
      "Layer 33\n",
      "tensor(-0.9937, device='cuda:0')\n",
      "Layer 34\n",
      "tensor(-0.9945, device='cuda:0')\n",
      "Layer 35\n",
      "tensor(-0.9944, device='cuda:0')\n",
      "Layer 0 vs. Layer 1\n",
      "tensor(0.4990, device='cuda:0')\n",
      "Layer 1 vs. Layer 2\n",
      "tensor(0.4581, device='cuda:0')\n",
      "Layer 2 vs. Layer 3\n",
      "tensor(0.2287, device='cuda:0')\n",
      "Layer 3 vs. Layer 4\n",
      "tensor(0.5493, device='cuda:0')\n",
      "Layer 4 vs. Layer 5\n",
      "tensor(0.5399, device='cuda:0')\n",
      "Layer 5 vs. Layer 6\n",
      "tensor(0.7394, device='cuda:0')\n",
      "Layer 6 vs. Layer 7\n",
      "tensor(0.7073, device='cuda:0')\n",
      "Layer 7 vs. Layer 8\n",
      "tensor(0.7958, device='cuda:0')\n",
      "Layer 8 vs. Layer 9\n",
      "tensor(0.7365, device='cuda:0')\n",
      "Layer 9 vs. Layer 10\n",
      "tensor(0.5993, device='cuda:0')\n",
      "Layer 10 vs. Layer 11\n",
      "tensor(0.6223, device='cuda:0')\n",
      "Layer 11 vs. Layer 12\n",
      "tensor(0.6529, device='cuda:0')\n",
      "Layer 12 vs. Layer 13\n",
      "tensor(0.5679, device='cuda:0')\n",
      "Layer 13 vs. Layer 14\n",
      "tensor(0.5805, device='cuda:0')\n",
      "Layer 14 vs. Layer 15\n",
      "tensor(0.5874, device='cuda:0')\n",
      "Layer 15 vs. Layer 16\n",
      "tensor(0.5223, device='cuda:0')\n",
      "Layer 16 vs. Layer 17\n",
      "tensor(0.4326, device='cuda:0')\n",
      "Layer 17 vs. Layer 18\n",
      "tensor(0.5437, device='cuda:0')\n",
      "Layer 18 vs. Layer 19\n",
      "tensor(0.4808, device='cuda:0')\n",
      "Layer 19 vs. Layer 20\n",
      "tensor(0.5288, device='cuda:0')\n",
      "Layer 20 vs. Layer 21\n",
      "tensor(0.6315, device='cuda:0')\n",
      "Layer 21 vs. Layer 22\n",
      "tensor(0.5422, device='cuda:0')\n",
      "Layer 22 vs. Layer 23\n",
      "tensor(0.5484, device='cuda:0')\n",
      "Layer 23 vs. Layer 24\n",
      "tensor(0.5210, device='cuda:0')\n",
      "Layer 24 vs. Layer 25\n",
      "tensor(0.5316, device='cuda:0')\n",
      "Layer 25 vs. Layer 26\n",
      "tensor(0.5050, device='cuda:0')\n",
      "Layer 26 vs. Layer 27\n",
      "tensor(0.6380, device='cuda:0')\n",
      "Layer 27 vs. Layer 28\n",
      "tensor(0.6122, device='cuda:0')\n",
      "Layer 28 vs. Layer 29\n",
      "tensor(0.6643, device='cuda:0')\n",
      "Layer 29 vs. Layer 30\n",
      "tensor(0.6426, device='cuda:0')\n",
      "Layer 30 vs. Layer 31\n",
      "tensor(0.6716, device='cuda:0')\n",
      "Layer 31 vs. Layer 32\n",
      "tensor(0.7186, device='cuda:0')\n",
      "Layer 32 vs. Layer 33\n",
      "tensor(0.7102, device='cuda:0')\n",
      "Layer 33 vs. Layer 34\n",
      "tensor(0.7700, device='cuda:0')\n",
      "Layer 34 vs. Layer 35\n",
      "tensor(0.6340, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for layer_idx in range(probe_model.shape[0]):\n",
    "    print(f\"Layer {layer_idx}\")\n",
    "    print(cos(probe_model[layer_idx, :, 0], probe_model[layer_idx, :, 1], dim=0))\n",
    "\n",
    "for layer_idx in range(probe_model.shape[0] - 1):\n",
    "    print(f\"Layer {layer_idx} vs. Layer {layer_idx + 1}\")\n",
    "    print(cos(probe_model[layer_idx, :, 1], probe_model[layer_idx + 1, :, 1], dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a46dbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_mlp_value_vecs(model):\n",
    "    mlp_value_vecs = [layer.mlp.down_proj.weight for layer in model.model.layers]\n",
    "    # [n_layers, d_mlp (11008), d_model (2048)]\n",
    "    return torch.stack(mlp_value_vecs, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6edbebf5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([36, 2048, 11008])\n",
      "Layer 0\n",
      "Layer 1\n",
      "Layer 2\n",
      "Layer 3\n",
      "Layer 4\n",
      "Layer 5\n",
      "Layer 6\n",
      "Layer 7\n",
      "Layer 8\n",
      "Layer 9\n",
      "Layer 10\n",
      "Layer 11\n",
      "Layer 12\n",
      "Layer 13\n",
      "Layer 14\n",
      "Layer 15\n",
      "Layer 16\n",
      "Layer 17\n",
      "Layer 18\n",
      "Layer 19\n",
      "Layer 20\n",
      "Layer 21\n",
      "Layer 22\n",
      "Layer 23\n",
      "Layer 24\n",
      "Layer 0\n",
      "Layer 1\n",
      "Layer 2\n",
      "Layer 3\n",
      "Layer 4\n",
      "Layer 5\n",
      "Layer 6\n",
      "Layer 7\n",
      "Layer 8\n",
      "Layer 9\n",
      "Layer 10\n",
      "Layer 11\n",
      "Layer 12\n",
      "Layer 13\n",
      "Layer 14\n",
      "Layer 15\n",
      "Layer 16\n",
      "Layer 17\n",
      "Layer 18\n",
      "Layer 19\n",
      "Layer 20\n",
      "Layer 21\n",
      "Layer 22\n",
      "Layer 23\n",
      "Layer 24\n",
      "Layer 25\n",
      "Layer 0\n",
      "Layer 1\n",
      "Layer 2\n",
      "Layer 3\n",
      "Layer 4\n",
      "Layer 5\n",
      "Layer 6\n",
      "Layer 7\n",
      "Layer 8\n",
      "Layer 9\n",
      "Layer 10\n",
      "Layer 11\n",
      "Layer 12\n",
      "Layer 13\n",
      "Layer 14\n",
      "Layer 15\n",
      "Layer 16\n",
      "Layer 17\n",
      "Layer 18\n",
      "Layer 19\n",
      "Layer 20\n",
      "Layer 21\n",
      "Layer 22\n",
      "Layer 23\n",
      "Layer 24\n",
      "Layer 25\n",
      "Layer 26\n",
      "Layer 0\n",
      "Layer 1\n",
      "Layer 2\n",
      "Layer 3\n",
      "Layer 4\n",
      "Layer 5\n",
      "Layer 6\n",
      "Layer 7\n",
      "Layer 8\n",
      "Layer 9\n",
      "Layer 10\n",
      "Layer 11\n",
      "Layer 12\n",
      "Layer 13\n",
      "Layer 14\n",
      "Layer 15\n",
      "Layer 16\n",
      "Layer 17\n",
      "Layer 18\n",
      "Layer 19\n",
      "Layer 20\n",
      "Layer 21\n",
      "Layer 22\n",
      "Layer 23\n",
      "Layer 24\n",
      "Layer 25\n",
      "Layer 26\n",
      "Layer 27\n",
      "Layer 0\n",
      "Layer 1\n",
      "Layer 2\n",
      "Layer 3\n",
      "Layer 4\n",
      "Layer 5\n",
      "Layer 6\n",
      "Layer 7\n",
      "Layer 8\n",
      "Layer 9\n",
      "Layer 10\n",
      "Layer 11\n",
      "Layer 12\n",
      "Layer 13\n",
      "Layer 14\n",
      "Layer 15\n",
      "Layer 16\n",
      "Layer 17\n",
      "Layer 18\n",
      "Layer 19\n",
      "Layer 20\n",
      "Layer 21\n",
      "Layer 22\n",
      "Layer 23\n",
      "Layer 24\n",
      "Layer 25\n",
      "Layer 26\n",
      "Layer 27\n",
      "Layer 28\n",
      "Layer 0\n",
      "Layer 1\n",
      "Layer 2\n",
      "Layer 3\n",
      "Layer 4\n",
      "Layer 5\n",
      "Layer 6\n",
      "Layer 7\n",
      "Layer 8\n",
      "Layer 9\n",
      "Layer 10\n",
      "Layer 11\n",
      "Layer 12\n",
      "Layer 13\n",
      "Layer 14\n",
      "Layer 15\n",
      "Layer 16\n",
      "Layer 17\n",
      "Layer 18\n",
      "Layer 19\n",
      "Layer 20\n",
      "Layer 21\n",
      "Layer 22\n",
      "Layer 23\n",
      "Layer 24\n",
      "Layer 25\n",
      "Layer 26\n",
      "Layer 27\n",
      "Layer 28\n",
      "Layer 29\n",
      "Layer 0\n",
      "Layer 1\n",
      "Layer 2\n",
      "Layer 3\n",
      "Layer 4\n",
      "Layer 5\n",
      "Layer 6\n",
      "Layer 7\n",
      "Layer 8\n",
      "Layer 9\n",
      "Layer 10\n",
      "Layer 11\n",
      "Layer 12\n",
      "Layer 13\n",
      "Layer 14\n",
      "Layer 15\n",
      "Layer 16\n",
      "Layer 17\n",
      "Layer 18\n",
      "Layer 19\n",
      "Layer 20\n",
      "Layer 21\n",
      "Layer 22\n",
      "Layer 23\n",
      "Layer 24\n",
      "Layer 25\n",
      "Layer 26\n",
      "Layer 27\n",
      "Layer 28\n",
      "Layer 29\n",
      "Layer 30\n",
      "Layer 0\n",
      "Layer 1\n",
      "Layer 2\n",
      "Layer 3\n",
      "Layer 4\n",
      "Layer 5\n",
      "Layer 6\n",
      "Layer 7\n",
      "Layer 8\n",
      "Layer 9\n",
      "Layer 10\n",
      "Layer 11\n",
      "Layer 12\n",
      "Layer 13\n",
      "Layer 14\n",
      "Layer 15\n",
      "Layer 16\n",
      "Layer 17\n",
      "Layer 18\n",
      "Layer 19\n",
      "Layer 20\n",
      "Layer 21\n",
      "Layer 22\n",
      "Layer 23\n",
      "Layer 24\n",
      "Layer 25\n",
      "Layer 26\n",
      "Layer 27\n",
      "Layer 28\n",
      "Layer 29\n",
      "Layer 30\n",
      "Layer 31\n",
      "Layer 0\n",
      "Layer 1\n",
      "Layer 2\n",
      "Layer 3\n",
      "Layer 4\n",
      "Layer 5\n",
      "Layer 6\n",
      "Layer 7\n",
      "Layer 8\n",
      "Layer 9\n",
      "Layer 10\n",
      "Layer 11\n",
      "Layer 12\n",
      "Layer 13\n",
      "Layer 14\n",
      "Layer 15\n",
      "Layer 16\n",
      "Layer 17\n",
      "Layer 18\n",
      "Layer 19\n",
      "Layer 20\n",
      "Layer 21\n",
      "Layer 22\n",
      "Layer 23\n",
      "Layer 24\n",
      "Layer 25\n",
      "Layer 26\n",
      "Layer 27\n",
      "Layer 28\n",
      "Layer 29\n",
      "Layer 30\n",
      "Layer 31\n",
      "Layer 32\n",
      "Layer 0\n",
      "Layer 1\n",
      "Layer 2\n",
      "Layer 3\n",
      "Layer 4\n",
      "Layer 5\n",
      "Layer 6\n",
      "Layer 7\n",
      "Layer 8\n",
      "Layer 9\n",
      "Layer 10\n",
      "Layer 11\n",
      "Layer 12\n",
      "Layer 13\n",
      "Layer 14\n",
      "Layer 15\n",
      "Layer 16\n",
      "Layer 17\n",
      "Layer 18\n",
      "Layer 19\n",
      "Layer 20\n",
      "Layer 21\n",
      "Layer 22\n",
      "Layer 23\n",
      "Layer 24\n",
      "Layer 25\n",
      "Layer 26\n",
      "Layer 27\n",
      "Layer 28\n",
      "Layer 29\n",
      "Layer 30\n",
      "Layer 31\n",
      "Layer 32\n",
      "Layer 33\n",
      "Layer 0\n",
      "Layer 1\n",
      "Layer 2\n",
      "Layer 3\n",
      "Layer 4\n",
      "Layer 5\n",
      "Layer 6\n",
      "Layer 7\n",
      "Layer 8\n",
      "Layer 9\n",
      "Layer 10\n",
      "Layer 11\n",
      "Layer 12\n",
      "Layer 13\n",
      "Layer 14\n",
      "Layer 15\n",
      "Layer 16\n",
      "Layer 17\n",
      "Layer 18\n",
      "Layer 19\n",
      "Layer 20\n",
      "Layer 21\n",
      "Layer 22\n",
      "Layer 23\n",
      "Layer 24\n",
      "Layer 25\n",
      "Layer 26\n",
      "Layer 27\n",
      "Layer 28\n",
      "Layer 29\n",
      "Layer 30\n",
      "Layer 31\n",
      "Layer 32\n",
      "Layer 33\n",
      "Layer 34\n",
      "Layer 0\n",
      "Layer 1\n",
      "Layer 2\n",
      "Layer 3\n",
      "Layer 4\n",
      "Layer 5\n",
      "Layer 6\n",
      "Layer 7\n",
      "Layer 8\n",
      "Layer 9\n",
      "Layer 10\n",
      "Layer 11\n",
      "Layer 12\n",
      "Layer 13\n",
      "Layer 14\n",
      "Layer 15\n",
      "Layer 16\n",
      "Layer 17\n",
      "Layer 18\n",
      "Layer 19\n",
      "Layer 20\n",
      "Layer 21\n",
      "Layer 22\n",
      "Layer 23\n",
      "Layer 24\n",
      "Layer 25\n",
      "Layer 26\n",
      "Layer 27\n",
      "Layer 28\n",
      "Layer 29\n",
      "Layer 30\n",
      "Layer 31\n",
      "Layer 32\n",
      "Layer 33\n",
      "Layer 34\n",
      "Layer 35\n",
      "Layer 0\n",
      "Layer 1\n",
      "Layer 2\n",
      "Layer 3\n",
      "Layer 4\n",
      "Layer 5\n",
      "Layer 6\n",
      "Layer 7\n",
      "Layer 8\n",
      "Layer 9\n",
      "Layer 10\n",
      "Layer 11\n",
      "Layer 12\n",
      "Layer 13\n",
      "Layer 14\n",
      "Layer 15\n",
      "Layer 16\n",
      "Layer 17\n",
      "Layer 18\n",
      "Layer 19\n",
      "Layer 20\n",
      "Layer 21\n",
      "Layer 22\n",
      "Layer 23\n",
      "Layer 24\n",
      "Layer 0\n",
      "Layer 1\n",
      "Layer 2\n",
      "Layer 3\n",
      "Layer 4\n",
      "Layer 5\n",
      "Layer 6\n",
      "Layer 7\n",
      "Layer 8\n",
      "Layer 9\n",
      "Layer 10\n",
      "Layer 11\n",
      "Layer 12\n",
      "Layer 13\n",
      "Layer 14\n",
      "Layer 15\n",
      "Layer 16\n",
      "Layer 17\n",
      "Layer 18\n",
      "Layer 19\n",
      "Layer 20\n",
      "Layer 21\n",
      "Layer 22\n",
      "Layer 23\n",
      "Layer 24\n",
      "Layer 25\n",
      "Layer 0\n",
      "Layer 1\n",
      "Layer 2\n",
      "Layer 3\n",
      "Layer 4\n",
      "Layer 5\n",
      "Layer 6\n",
      "Layer 7\n",
      "Layer 8\n",
      "Layer 9\n",
      "Layer 10\n",
      "Layer 11\n",
      "Layer 12\n",
      "Layer 13\n",
      "Layer 14\n",
      "Layer 15\n",
      "Layer 16\n",
      "Layer 17\n",
      "Layer 18\n",
      "Layer 19\n",
      "Layer 20\n",
      "Layer 21\n",
      "Layer 22\n",
      "Layer 23\n",
      "Layer 24\n",
      "Layer 25\n",
      "Layer 26\n",
      "Layer 0\n",
      "Layer 1\n",
      "Layer 2\n",
      "Layer 3\n",
      "Layer 4\n",
      "Layer 5\n",
      "Layer 6\n",
      "Layer 7\n",
      "Layer 8\n",
      "Layer 9\n",
      "Layer 10\n",
      "Layer 11\n",
      "Layer 12\n",
      "Layer 13\n",
      "Layer 14\n",
      "Layer 15\n",
      "Layer 16\n",
      "Layer 17\n",
      "Layer 18\n",
      "Layer 19\n",
      "Layer 20\n",
      "Layer 21\n",
      "Layer 22\n",
      "Layer 23\n",
      "Layer 24\n",
      "Layer 25\n",
      "Layer 26\n",
      "Layer 27\n",
      "Layer 0\n",
      "Layer 1\n",
      "Layer 2\n",
      "Layer 3\n",
      "Layer 4\n",
      "Layer 5\n",
      "Layer 6\n",
      "Layer 7\n",
      "Layer 8\n",
      "Layer 9\n",
      "Layer 10\n",
      "Layer 11\n",
      "Layer 12\n",
      "Layer 13\n",
      "Layer 14\n",
      "Layer 15\n",
      "Layer 16\n",
      "Layer 17\n",
      "Layer 18\n",
      "Layer 19\n",
      "Layer 20\n",
      "Layer 21\n",
      "Layer 22\n",
      "Layer 23\n",
      "Layer 24\n",
      "Layer 25\n",
      "Layer 26\n",
      "Layer 27\n",
      "Layer 28\n",
      "Layer 0\n",
      "Layer 1\n",
      "Layer 2\n",
      "Layer 3\n",
      "Layer 4\n",
      "Layer 5\n",
      "Layer 6\n",
      "Layer 7\n",
      "Layer 8\n",
      "Layer 9\n",
      "Layer 10\n",
      "Layer 11\n",
      "Layer 12\n",
      "Layer 13\n",
      "Layer 14\n",
      "Layer 15\n",
      "Layer 16\n",
      "Layer 17\n",
      "Layer 18\n",
      "Layer 19\n",
      "Layer 20\n",
      "Layer 21\n",
      "Layer 22\n",
      "Layer 23\n",
      "Layer 24\n",
      "Layer 25\n",
      "Layer 26\n",
      "Layer 27\n",
      "Layer 28\n",
      "Layer 29\n",
      "Layer 0\n",
      "Layer 1\n",
      "Layer 2\n",
      "Layer 3\n",
      "Layer 4\n",
      "Layer 5\n",
      "Layer 6\n",
      "Layer 7\n",
      "Layer 8\n",
      "Layer 9\n",
      "Layer 10\n",
      "Layer 11\n",
      "Layer 12\n",
      "Layer 13\n",
      "Layer 14\n",
      "Layer 15\n",
      "Layer 16\n",
      "Layer 17\n",
      "Layer 18\n",
      "Layer 19\n",
      "Layer 20\n",
      "Layer 21\n",
      "Layer 22\n",
      "Layer 23\n",
      "Layer 24\n",
      "Layer 25\n",
      "Layer 26\n",
      "Layer 27\n",
      "Layer 28\n",
      "Layer 29\n",
      "Layer 30\n",
      "Layer 0\n",
      "Layer 1\n",
      "Layer 2\n",
      "Layer 3\n",
      "Layer 4\n",
      "Layer 5\n",
      "Layer 6\n",
      "Layer 7\n",
      "Layer 8\n",
      "Layer 9\n",
      "Layer 10\n",
      "Layer 11\n",
      "Layer 12\n",
      "Layer 13\n",
      "Layer 14\n",
      "Layer 15\n",
      "Layer 16\n",
      "Layer 17\n",
      "Layer 18\n",
      "Layer 19\n",
      "Layer 20\n",
      "Layer 21\n",
      "Layer 22\n",
      "Layer 23\n",
      "Layer 24\n",
      "Layer 25\n",
      "Layer 26\n",
      "Layer 27\n",
      "Layer 28\n",
      "Layer 29\n",
      "Layer 30\n",
      "Layer 31\n",
      "Layer 0\n",
      "Layer 1\n",
      "Layer 2\n",
      "Layer 3\n",
      "Layer 4\n",
      "Layer 5\n",
      "Layer 6\n",
      "Layer 7\n",
      "Layer 8\n",
      "Layer 9\n",
      "Layer 10\n",
      "Layer 11\n",
      "Layer 12\n",
      "Layer 13\n",
      "Layer 14\n",
      "Layer 15\n",
      "Layer 16\n",
      "Layer 17\n",
      "Layer 18\n",
      "Layer 19\n",
      "Layer 20\n",
      "Layer 21\n",
      "Layer 22\n",
      "Layer 23\n",
      "Layer 24\n",
      "Layer 25\n",
      "Layer 26\n",
      "Layer 27\n",
      "Layer 28\n",
      "Layer 29\n",
      "Layer 30\n",
      "Layer 31\n",
      "Layer 32\n",
      "Layer 0\n",
      "Layer 1\n",
      "Layer 2\n",
      "Layer 3\n",
      "Layer 4\n",
      "Layer 5\n",
      "Layer 6\n",
      "Layer 7\n",
      "Layer 8\n",
      "Layer 9\n",
      "Layer 10\n",
      "Layer 11\n",
      "Layer 12\n",
      "Layer 13\n",
      "Layer 14\n",
      "Layer 15\n",
      "Layer 16\n",
      "Layer 17\n",
      "Layer 18\n",
      "Layer 19\n",
      "Layer 20\n",
      "Layer 21\n",
      "Layer 22\n",
      "Layer 23\n",
      "Layer 24\n",
      "Layer 25\n",
      "Layer 26\n",
      "Layer 27\n",
      "Layer 28\n",
      "Layer 29\n",
      "Layer 30\n",
      "Layer 31\n",
      "Layer 32\n",
      "Layer 33\n",
      "Layer 0\n",
      "Layer 1\n",
      "Layer 2\n",
      "Layer 3\n",
      "Layer 4\n",
      "Layer 5\n",
      "Layer 6\n",
      "Layer 7\n",
      "Layer 8\n",
      "Layer 9\n",
      "Layer 10\n",
      "Layer 11\n",
      "Layer 12\n",
      "Layer 13\n",
      "Layer 14\n",
      "Layer 15\n",
      "Layer 16\n",
      "Layer 17\n",
      "Layer 18\n",
      "Layer 19\n",
      "Layer 20\n",
      "Layer 21\n",
      "Layer 22\n",
      "Layer 23\n",
      "Layer 24\n",
      "Layer 25\n",
      "Layer 26\n",
      "Layer 27\n",
      "Layer 28\n",
      "Layer 29\n",
      "Layer 30\n",
      "Layer 31\n",
      "Layer 32\n",
      "Layer 33\n",
      "Layer 34\n",
      "Layer 0\n",
      "Layer 1\n",
      "Layer 2\n",
      "Layer 3\n",
      "Layer 4\n",
      "Layer 5\n",
      "Layer 6\n",
      "Layer 7\n",
      "Layer 8\n",
      "Layer 9\n",
      "Layer 10\n",
      "Layer 11\n",
      "Layer 12\n",
      "Layer 13\n",
      "Layer 14\n",
      "Layer 15\n",
      "Layer 16\n",
      "Layer 17\n",
      "Layer 18\n",
      "Layer 19\n",
      "Layer 20\n",
      "Layer 21\n",
      "Layer 22\n",
      "Layer 23\n",
      "Layer 24\n",
      "Layer 25\n",
      "Layer 26\n",
      "Layer 27\n",
      "Layer 28\n",
      "Layer 29\n",
      "Layer 30\n",
      "Layer 31\n",
      "Layer 32\n",
      "Layer 33\n",
      "Layer 34\n",
      "Layer 35\n"
     ]
    }
   ],
   "source": [
    "\n",
    "value_vecs = get_mlp_value_vecs(actor)\n",
    "print(value_vecs.shape)\n",
    "\n",
    "top_cos_scores = {0: [], 1: []}\n",
    "for target_label in [0, 1]:\n",
    "    for target_probe_layer in range(24, 36):\n",
    "        target_probe = probe_model[target_probe_layer, :, target_label]\n",
    "\n",
    "        for layer_idx in range(0, target_probe_layer + 1):\n",
    "            print(f\"Layer {layer_idx}\")\n",
    "            cos_scores = cos(value_vecs[layer_idx], target_probe.unsqueeze(-1), dim=0)\n",
    "            _topk = cos_scores.topk(k=100)\n",
    "            _values = [x.item() for x in _topk.values]\n",
    "            _idxs = [x.item() for x in _topk.indices]\n",
    "            topk = list(\n",
    "                zip(\n",
    "                    _values,\n",
    "                    _idxs,\n",
    "                    [target_probe_layer] * _topk.indices.shape[0],\n",
    "                    [layer_idx] * _topk.indices.shape[0],\n",
    "                )\n",
    "            )\n",
    "            top_cos_scores[target_label].extend(topk)\n",
    "\n",
    "sorted_scores_0 = sorted(top_cos_scores[0], key=lambda x: x[0], reverse=True)\n",
    "sorted_scores_1 = sorted(top_cos_scores[1], key=lambda x: x[0], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d29f3b14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 5650)\n",
      "0.2273489236831665\n",
      "[' não', ' nicht', '不', '不在', ' không', '不会', ' не', ' 不', '不會', '不是一个']\n",
      "(24, 5159)\n",
      "0.19371235370635986\n",
      "['圬', 'ableObject', 'utow', 'lops', ' \\n \\n', 'enci', 'ENTE', 'バイ', '调', 'fce']\n",
      "(32, 767)\n",
      "0.1869061291217804\n",
      "[' không', '没有', ' nicht', ' not', '不会', '不能', ' neither', ' não', 'ไม', '沒有']\n",
      "(30, 6404)\n",
      "0.1857713907957077\n",
      "['不是', '并非', ' not', '不是一个', '也不是', 'not', ' NOT', '\\tnot', '并不是', '不再是']\n",
      "(26, 744)\n",
      "0.18252520263195038\n",
      "['未能', '不够', ' nicht', '不像', '达不到', '不清楚', '不具备', '不到位', '不符', '还不']\n",
      "(31, 10127)\n",
      "0.1824290007352829\n",
      "[' not', ' không', ' nicht', '不会', '不能', '不是', ' не', 'not', '\\tnot', ' não']\n",
      "(26, 6619)\n",
      "0.16895824670791626\n",
      "['缺乏', '缺少', '不方便', ' lacks', '难以', '未能', '无法', ' lack', '得不到', '不符合']\n",
      "(30, 10722)\n",
      "0.1651017963886261\n",
      "['不会', '不會', '也不会', '都不会', ' doesn', '并不会', ' neither', ' doesnt', ' nicht', ' never']\n",
      "(23, 10504)\n",
      "0.1642017960548401\n",
      "['yro', '_Global', '糠', '有色', ' genie', '�回', ' kd', 'onio', '但如果', '冉']\n",
      "(27, 9766)\n",
      "0.16189239919185638\n",
      "['是不可能', ' neither', '看不到', '不存在', '是不会', ' nowhere', ' nothing', ' none', '没有任何', '都没有']\n",
      "(24, 8572)\n",
      "0.16155752539634705\n",
      "['thèque', 'ばかり', '每次', '一次次', '每次都', 'pector', 'imiters', '列表', 'oping', ' Libraries']\n",
      "(27, 4971)\n",
      "0.15917938947677612\n",
      "[' inefficient', '没能', 'inity', '不方便', 'Danger', ' disadvantage', '不利于', '还不如', ' challenged', 'ขาด']\n",
      "(26, 5285)\n",
      "0.15913885831832886\n",
      "['没有', '并没有', '不曾', '不会有', '不存在', ' nowhere', '沒有', ' never', '都没有', '不会']\n",
      "(23, 4801)\n",
      "0.15832751989364624\n",
      "[' Roller', 'ottom', ' AC', ' Barcode', 'SHARE', 'ード', 'odon', 'ollar', ' ogl', 'assert']\n",
      "(28, 1960)\n",
      "0.15619516372680664\n",
      "['不是', '不是一个', ' not', ' nicht', ' không', ' isn', '不会', ' NOT', '不要', ' не']\n",
      "(31, 8337)\n",
      "0.15450599789619446\n",
      "['不', ' nicht', ' not', ' não', ' không', '不太', '不会', ' less', '\\tnot', ' 不']\n",
      "(25, 9748)\n",
      "0.15408319234848022\n",
      "[' lacks', ' lacked', '无力', '达不到', '缺乏', '缺少', '还没有', '根本没有', '未能', 'Limited']\n",
      "(23, 6804)\n",
      "0.1524103283882141\n",
      "['失望', ' :(', '悲哀', '黯', '无奈', ' disappointing', ' unfavor', '失效', '遗憾', ' sad']\n",
      "(31, 8959)\n",
      "0.14910438656806946\n",
      "['非', ' non', 'non', 'Non', ' Non', '.non', '-non', '(non', '_non', ' NON']\n",
      "(27, 1455)\n",
      "0.14875751733779907\n",
      "['不同于', '≠', ' different', '不同的', 'different', '不一样的', '!=', '不同', ' diferente', ' nonzero']\n",
      "(25, 3521)\n",
      "0.14824405312538147\n",
      "['_;', ';', ';;;;', 'post', '__;', '\";', '；', ' Cop', ' post', ';c']\n",
      "(24, 3986)\n",
      "0.14724688231945038\n",
      "[' Worse', ' worse', '还不如', 'culate', ' inadequate', '达不到', '劣', ' hardest', ' fails', '得不到']\n",
      "(28, 9982)\n",
      "0.1470814049243927\n",
      "[' neither', ' not', ' không', ' nicht', '不是一个', ' não', '不会', '不是', '不會', '不像']\n",
      "(30, 1911)\n",
      "0.14617487788200378\n",
      "['不在', '不', '不像', ' doesn', 'doesn', ' isn', '不说', '不来', '不是', '不开']\n",
      "(19, 4327)\n",
      "0.14438167214393616\n",
      "['[]{\"', '帝国', '�', 'isure', ' Synthetic', ' Genuine', ' imperial', '后排', '绒', 'FORE']\n",
      "(22, 4710)\n",
      "0.14384090900421143\n",
      "[' apart', 'on', ' Und', 'onné', 'bei', 'old', 'OLD', 'ambda', '老', 'FX']\n",
      "(23, 1482)\n",
      "0.1437261402606964\n",
      "['yre', '成交', '刚', 'aldi', 'lasses', 'alker', '/admin', '��', 'ật', 'ảng']\n",
      "(24, 5866)\n",
      "0.1428830772638321\n",
      "['izi', 'ipi', '涯', 'orderid', ' sights', 'entic', 'Pod', ' misses', ' subsid', '_blueprint']\n",
      "(25, 2929)\n",
      "0.1427357792854309\n",
      "['lemen', ' Crane', 'ewn', 'fieldset', ' fort', ' sigh', 'fort', 'Fort', 'nu', '、、']\n",
      "(24, 17)\n",
      "0.141063392162323\n",
      "['还是要', '孬', '烦', '%\");\\n', '/Register', 'kaza', 'izen', '-register', '邋', '放射']\n",
      "(25, 8947)\n",
      "0.1401899755001068\n",
      "['未能', '也不能', '不能', ' inability', '没能', ' Worse', ' Unable', '难以', '无法', '得不到']\n",
      "(26, 10194)\n",
      "0.13975676894187927\n",
      "['无效', '::~', '落后', ' unavailable', ' indirect', 'unable', '不合格', '异', '为空', ' dysfunctional']\n",
      "(20, 3644)\n",
      "0.13974617421627045\n",
      "[' :(', ' Unable', '只好', 'inem', '偏', '导致', ' best', '!', ' due', ' ham']\n",
      "(24, 5706)\n",
      "0.13824336230754852\n",
      "['less', '但在', '但我们', '但他们', 'lessness', ',but', ' nowhere', ' but', ' BUT', '但从']\n",
      "(24, 521)\n",
      "0.13817307353019714\n",
      "['乃至', '接着', 'unities', 'inue', '…and', '.decode', '搦', 'dana', '醭', '스크']\n",
      "(28, 9832)\n",
      "0.137555330991745\n",
      "['没有', '也没有', ' neither', '都没有', '不存在', '并没有', '缺乏', '不具备', ' lacks', ' lack']\n",
      "(30, 7148)\n",
      "0.13754361867904663\n",
      "[' not', '不是', '不是一个', ' nicht', '\\tnot', '不像', 'not', ' không', ' não', '不是很']\n",
      "(25, 1956)\n",
      "0.13741639256477356\n",
      "['不能', ' nobody', ' never', ' nowhere', '不具备', '看不到', '不会', '不存在', 'cannot', '不會']\n",
      "(31, 6167)\n",
      "0.13422220945358276\n",
      "[' (', ' （', '（', ' (_', ' ((', ' (.', ' ({', ' (`', ' ($', '(']\n",
      "(30, 7620)\n",
      "0.13393504917621613\n",
      "[' not', 'not', '\\tnot', ' NOT', ' Not', 'Not', '_not', '不是', '.not', 'NOT']\n",
      "(25, 2253)\n",
      "0.13336943089962006\n",
      "['能力和', ';%', ';r', ' furthermore', ' coupled', 'igor', '并且', ';k', '…and', 'fra']\n",
      "(24, 9229)\n",
      "0.1326795220375061\n",
      "['苦恼', '犯规', '不合格', ' failing', ' disadvantage', '烦恼', '混淆', ' Hurt', ' disappointed', ' impair']\n",
      "(25, 9704)\n",
      "0.13263463973999023\n",
      "[' 和', '和', '和个人', ' 或', 'aten', 'lat', '胼', 'bout', 'ussels', 'site']\n",
      "(25, 9178)\n",
      "0.13255369663238525\n",
      "[';', '_;', '；', ' \"\";', ';,', \";',\", ';;', ';;;;', ' \",\"', \";',\\n\"]\n",
      "(24, 3043)\n",
      "0.13253739476203918\n",
      "['以及', ' 있고', '咤', ' {};', '再说', 'usk', '筇', ' plus', ' deposition', ' oraz']\n",
      "(24, 58)\n",
      "0.1325191855430603\n",
      "['遭', '不利', ' complic', '严重影响', '不公平', '严重', '严重的', ' suffer', ' :(', ' unfortunately']\n",
      "(28, 7779)\n",
      "0.1324859857559204\n",
      "['resco', 'anoi', '未必', '不忍', 'inker', 'dbl', ' Dense', ' announcement', '不代表', 'oi']\n",
      "(24, 10990)\n",
      "0.13216501474380493\n",
      "['Dam', 'uilt', 'Doctrine', '婿', 'COM', 'put', 'descriptor', '次', '口头', 'neas']\n",
      "(25, 2731)\n",
      "0.13204707205295563\n",
      "['\";', '”;', ' \");', ' \";', '\");', '`;', \"');\", \" ');\", ');\\\\\\n', '\"];']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "seen = []\n",
    "for elem in sorted_scores_0[:100]:\n",
    "    cos_score, mlp_idx, probe_layer_idx, layer_idx = elem\n",
    "    curr = (layer_idx, mlp_idx)\n",
    "    if curr in seen:\n",
    "        continue\n",
    "    seen.append(curr)\n",
    "    print(curr)\n",
    "    print(cos_score)\n",
    "    print(\n",
    "        unembed_text(\n",
    "            actor.model.layers[layer_idx].mlp.down_proj.weight[:, mlp_idx],\n",
    "            actor.lm_head.weight,\n",
    "            actor.tokenizer,\n",
    "            k=10,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f8f2419",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23, 3143)\n",
      "24\n",
      "0.26678231358528137\n",
      "['闼', 'elif', ' piger', '.Suppress', '_BLOCKS', '锥', '煳', ' TSR', ' Thumb', 'hä']\n",
      "(26, 6475)\n",
      "26\n",
      "0.26015180349349976\n",
      "['倒是', '不失', '适度', 'successful', '.success', '却是', ' successful', '没事', '完好', '还不错']\n",
      "(26, 3665)\n",
      "26\n",
      "0.23566988110542297\n",
      "['урс', 'swick', '然而', 'ulton', '最新', '�', '半个', 'iox', '然', '但是']\n",
      "(28, 10153)\n",
      "32\n",
      "0.21838121116161346\n",
      "['uito', 'Todo', 'mdi', 'それで', 'ISR', 'jal', 'odd', 'jn', 'todo', '_lite']\n",
      "(22, 4606)\n",
      "24\n",
      "0.19218069314956665\n",
      "['-banner', '<small', 'Rare', '(fin', '.bits', 'ocode', '大大小', 'lij', ' Finch', '_fin']\n",
      "(31, 3311)\n",
      "32\n",
      "0.18836161494255066\n",
      "['eworthy', 'uele', 'edio', '圄', 'aroo', '��', '迨', 'uptools', 'etheless', ' INTERN']\n",
      "(26, 4334)\n",
      "26\n",
      "0.18598763644695282\n",
      "['iston', 'StackSize', 'ISIBLE', 'てくれ', '|int', 'ут', '几分', ' TER', 'TERN', '藻']\n",
      "(29, 6676)\n",
      "29\n",
      "0.18184325098991394\n",
      "[' yes', ' Yes', 'Bindable', ' exactly', 'Yes', '\"Yes', 'yes', ' Yep', ' Exactly', ' included']\n",
      "(35, 8199)\n",
      "35\n",
      "0.1802186369895935\n",
      "['uele', 'nis', '饥饿', '一路', 'wing', ' eas', 'illez', ' Wing', 'ucus', \"'re\"]\n",
      "(31, 3867)\n",
      "32\n",
      "0.1801324188709259\n",
      "['ONO', 'HING', '也只能', ' (*((', 'endcode', '迨', 'andum', 'uele', '-horizontal', ' inve']\n",
      "(26, 8920)\n",
      "26\n",
      "0.1781361699104309\n",
      "[' greater', '过渡', '::', ' @', '只是', '##', 'icho', '更多', '更多的', '::_']\n",
      "(25, 8090)\n",
      "25\n",
      "0.17682482302188873\n",
      "['', '.)\\n\\n\\n\\n', '.\"\\n\\n', '.)\\n\\n', 'rk', '.\"\\n\\n\\n\\n', 'cis', '\".\\n\\n\\n\\n', '\":\"\"', '@\\n\\n']\n",
      "(25, 1124)\n",
      "25\n",
      "0.17384660243988037\n",
      "['ELY', '怫', 'yes', ' Awesome', 'itchen', '没错', 'etur', '即时发生', 'ños', 'emade']\n",
      "(25, 7384)\n",
      "28\n",
      "0.17369113862514496\n",
      "['一定程度', '面积约', '值得一', '땅', 'ockets', 'كور', 'Conta', 'ordes', '�', '傍']\n",
      "(27, 10388)\n",
      "27\n",
      "0.17276860773563385\n",
      "[' mirac', '乐观', '安然', ' Relief', '幸', '.isSuccess', '.SUCCESS', ' favorable', '优点', '顺利']\n",
      "(31, 4851)\n",
      "33\n",
      "0.17077018320560455\n",
      "['CAF', 'bió', 'WithValue', 'PFN', 'isque', 'CTS', 'nda', ' المص', ' Tup', '(\"(%']\n",
      "(27, 3870)\n",
      "28\n",
      "0.17022138833999634\n",
      "['力还是', '偻', '|{\\n', 'oling', 'кри', '.TRUE', '.must', 'moid', '_GRANTED', 'weetalert']\n",
      "(27, 4114)\n",
      "27\n",
      "0.16951915621757507\n",
      "['oux', 'antas', 'hook', 'ectl', 'INTR', 'INGTON', 'PEND', ' Blonde', 'tee', 'mb']\n",
      "(26, 7492)\n",
      "32\n",
      "0.16649653017520905\n",
      "['awns', ' pandas', 'urent', 'oose', 'кажет', 'atra', '��', 'буд', 'azz', '_mono']\n",
      "(30, 2041)\n",
      "31\n",
      "0.16617873311042786\n",
      "['一体', '.addComponent', '俍', '椓', ' comparable', \"$_['\", '荒', '{-', 'addComponent', '僧']\n",
      "(24, 4521)\n",
      "24\n",
      "0.16544432938098907\n",
      "[' Votes', '的那个', '隈', '的确', 'граф', 'odel', 'MLE', '_rm', 'door', '曾經']\n",
      "(25, 1974)\n",
      "27\n",
      "0.1627085655927658\n",
      "['美妙', '就好了', 'okay', ' ok', ' lifes', ' manageable', '通畅', ' okay', '-ok', '不错的']\n",
      "(25, 9809)\n",
      "26\n",
      "0.16001416742801666\n",
      "['放心', '感激', ' compliment', '_Right', ' Balance', ' enh', 'Balance', '倭', ' grâce', 'วด']\n",
      "(30, 8233)\n",
      "35\n",
      "0.1583629846572876\n",
      "[' correctly', '正确', '恰当', ' accurately', '符合', '合适', ' properly', ' adequately', '准确', ' accurate']\n",
      "(28, 11)\n",
      "28\n",
      "0.1577838659286499\n",
      "['通畅', ' happiness', '完好', '顺利', ' onSuccess', '教学质量', ' cleanliness', '身体健康', '完整性', '愉快']\n",
      "(25, 1039)\n",
      "25\n",
      "0.156415656208992\n",
      "['�', '更有', '更为', '讨', '胜', '接管', ' Regents', ')..', ' hơn', ' viewpoint']\n",
      "(31, 4729)\n",
      "32\n",
      "0.1548871099948883\n",
      "['uito', 'ueling', ' dú', ' superf', ' kiệm', '贫', '@testable', ' INCIDENT', '격', 'ersh']\n",
      "(25, 10381)\n",
      "26\n",
      "0.15287891030311584\n",
      "[' nhờ', 'antu', 'SingleNode', '惊喜', '就好了', '不至于', 'Subset', 'antas', ' PROVIDED', '端正']\n",
      "(25, 3774)\n",
      "25\n",
      "0.1518336832523346\n",
      "['.\\n\\n\\n\\n', '.\"\\n\\n\\n', '.\"\\n\\n\\n\\n', ' .\\n\\n\\n\\n', '.\\n\\n\\n', ').\\n\\n\\n\\n', '.)\\n\\n', '.\\n\\n\\n\\n\\n\\n', '也不例外', '.)\\n\\n\\n\\n']\n",
      "(24, 2231)\n",
      "26\n",
      "0.15169212222099304\n",
      "[' endorsement', ' endorsements', '正面', 'حيا', '[++', 'sume', ' unconditional', ' boosted', '�', '臾']\n",
      "(23, 7046)\n",
      "24\n",
      "0.15148961544036865\n",
      "['ROPERTY', 'Luck', 'mirror', 'ío', '下來', 'umu', '招呼', 'indle', ' inevitable', 'ForeColor']\n",
      "(27, 6855)\n",
      "32\n",
      "0.15030312538146973\n",
      "['HING', 'uito', 'pio', ' ];\\r\\n', 'odd', '-md', 'pole', 'endale', 'shouldBe', 'ator']\n",
      "(35, 6751)\n",
      "35\n",
      "0.1493704468011856\n",
      "['}->', '\\\\:', '},\"', '],&', '}[', '}};\\n', ']\\\\\\\\', '},{\"', '}\\\\\\\\', \"]='\"]\n",
      "(26, 6117)\n",
      "26\n",
      "0.14909419417381287\n",
      "[\".'\\n\\n\", '.)\\n\\n', '!).\\n\\n', '---\\n\\n', '.\")\\n\\n', '.).\\n\\n', '.\"\\n\\n', '.\"\\n\\n\\n', '!\"\\n\\n', '-----\\n\\n']\n",
      "(24, 9090)\n",
      "26\n",
      "0.14880356192588806\n",
      "['有时候', ' sometimes', ' Might', ' ARGS', ' occasionally', '-aut', '_Arg', ' might', ' Sometimes', 'atile']\n",
      "(23, 6496)\n",
      "24\n",
      "0.14798703789710999\n",
      "['不至于', ' spared', '.MODEL', '就好了', 'ystate', ' healthier', '豁', '没事', '有益', '有信心']\n",
      "(30, 906)\n",
      "32\n",
      "0.14675985276699066\n",
      "['óc', ' framing', 'ession', '>(*', 'ogie', 'msgs', 'stice', 'opo', ' Особенно', ' Patterson']\n",
      "(22, 547)\n",
      "24\n",
      "0.1425533890724182\n",
      "['新三', 'itivity', \".';\\n\", '[];\\r\\n', '手中', 'Enumeration', 'efa', '�', 'eken', '-column']\n",
      "(25, 7613)\n",
      "25\n",
      "0.1418973207473755\n",
      "['\":\"\"', ' BCE', '*/\\n\\n', ' *\\\\', ' Fletcher', '//**\\n', 'IllegalAccessException', '.*/\\n', '}*/\\n\\n', '汴']\n",
      "(25, 1688)\n",
      "28\n",
      "0.14108476042747498\n",
      "[' OK', ' Brilliant', 'edList', 'okay', '好消息', ' ok', ' nice', '的优点', '敬业', 'rike']\n",
      "(25, 7321)\n",
      "27\n",
      "0.14087256789207458\n",
      "[' nucleus', 'lla', '#${', '占地', 'XmlAttribute', '的信任', 'ething', '.link', 'ms', 'بو']\n",
      "(26, 8416)\n",
      "32\n",
      "0.14061081409454346\n",
      "['mens', ' ogl', 'IfExists', 'atte', 'ไร', ' Ceremony', ' Berk', 'pole', 'icals', 'Hum']\n",
      "(26, 9684)\n",
      "26\n",
      "0.1397687792778015\n",
      "['体贴', '舒服', '不至于', '_ACCEPT', '不惜', 'tractive', 'qli', '顺畅', '充裕', '通畅']\n",
      "(25, 833)\n",
      "25\n",
      "0.13904884457588196\n",
      "['！」', 'rather', ' rather', 'ighting', '.RIGHT', '？」', '取', ' Therefore', 'omet', '故']\n",
      "(27, 10369)\n",
      "27\n",
      "0.1386399269104004\n",
      "[' safe', '-safe', '_safe', 'safe', '顺畅', '幸', ' safest', ' Safe', ' blessed', ' mirac']\n",
      "(29, 4028)\n",
      "29\n",
      "0.1386210024356842\n",
      "['|{\\n', '必', 'ött', 'unque', '.boolean', '.Misc', 'INCT', 'esz', 'essel', '必备']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "seen = []\n",
    "for elem in sorted_scores_1[:100]:\n",
    "    cos_score, mlp_idx, probe_layer_idx, layer_idx = elem\n",
    "    curr = (layer_idx, mlp_idx)\n",
    "    if curr in seen:\n",
    "        continue\n",
    "    seen.append(curr)\n",
    "    print(curr)\n",
    "    print(probe_layer_idx)\n",
    "    print(cos_score)\n",
    "    print(\n",
    "        unembed_text(\n",
    "            actor.model.layers[layer_idx].mlp.down_proj.weight[:, mlp_idx],\n",
    "            actor.lm_head.weight,\n",
    "            actor.tokenizer,\n",
    "            k=10,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107ac253",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\n",
    "    cos(\n",
    "        actor.model.layers[25].mlp.down_proj.weight[:, 7613],\n",
    "        actor.model.layers[25].mlp.down_proj.weight[:, 1688],\n",
    "        dim=0,\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\n",
    "    cos(\n",
    "        actor.model.layers[25].mlp.down_proj.weight[:, 7613],\n",
    "        probe_model[25, :, 1],\n",
    "        dim=0,\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\n",
    "    cos(\n",
    "        actor.model.layers[25].mlp.down_proj.weight[:, 1688],\n",
    "        probe_model[25, :, 1],\n",
    "        dim=0,\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\n",
    "    cos(\n",
    "        actor.model.layers[25].mlp.down_proj.weight[:, 1688]\n",
    "        + actor.model.layers[25].mlp.down_proj.weight[:, 7613],\n",
    "        probe_model[25, :, 1],\n",
    "        dim=0,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0910e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mlp_idxs = [1688, 7613, 9748, 3521, 2929, 8947]\n",
    "\n",
    "for offset in range(1, len(mlp_idxs)):\n",
    "    added = actor.model.layers[25].mlp.down_proj.weight[:, mlp_idxs[:offset]].sum(dim=1)\n",
    "\n",
    "    print(\n",
    "        unembed_text(\n",
    "            added,\n",
    "            # actor.model.layers[25].mlp.down_proj.weight[:, 1688]\n",
    "            # + actor.model.layers[25].mlp.down_proj.weight[:, 7613],\n",
    "            actor.lm_head.weight,\n",
    "            actor.tokenizer,\n",
    "            k=10,\n",
    "        )\n",
    "    )\n",
    "    print(cos(added, probe_model[25, :, 1], dim=0))\n",
    "\n",
    "# [28, 10153]\n",
    "# [29, 6676]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0008f8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 9, 300, 11008])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5aff2e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 9, 300, 11008])\n",
      "torch.Size([4, 9, 300, 11008])\n",
      "torch.Size([4, 9, 300, 11008])\n",
      "torch.Size([4, 9, 300, 11008])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mlp_layers = list(range(24, 36))\n",
    "record_module_names = [f\"model.layers.{i}.mlp.act_fn\" for i in mlp_layers]\n",
    "max_new_tokens = config[\"max_response_length\"]\n",
    "tokenizer = actor.tokenizer\n",
    "token_open = tokenizer.encode(\" (\")[0]  # 320\n",
    "token_not = tokenizer.encode(\"not\")[0]  # 1921\n",
    "token_this = tokenizer.encode(\"this\")[0]  # 574\n",
    "\n",
    "\n",
    "not_acts = []\n",
    "this_acts = []\n",
    "for batch_idx, batch in enumerate(valid_dataloader):\n",
    "\n",
    "    input_ids = batch[\"input_ids\"].cuda()\n",
    "    attention_mask = batch[\"attention_mask\"].cuda()\n",
    "\n",
    "    with record_activations(actor, record_module_names) as recording:\n",
    "        output = actor.generate(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            generation_config=generation_config,\n",
    "            output_scores=False,  # this is potentially very large\n",
    "            return_dict_in_generate=True,\n",
    "            use_cache=True,\n",
    "        )\n",
    "\n",
    "    # len(recording[\"model.layers.0\"]): max_response_length\n",
    "    # recording[\"model.layers.0\"][0].shape: [batch, prompt_length, d_model]\n",
    "    # recording[\"model.layers.0\"][1].shape: [batch, 1, d_model]\n",
    "    recording = {\n",
    "        layer_name: torch.cat(acts, dim=1) for layer_name, acts in recording.items()\n",
    "    }\n",
    "\n",
    "    # recording[\"model.layers.0\"].shape:\n",
    "    # [batch, prompt_length + max_new_tokens, d_mlp]\n",
    "    seq = output.sequences\n",
    "    response = seq[:, -max_new_tokens:]\n",
    "    response_text = tokenizer.batch_decode(seq, skip_special_tokens=True)\n",
    "\n",
    "    # [batch, n_layers, response_length, d_mlp]\n",
    "    activations = torch.stack(\n",
    "        [acts[:, -max_new_tokens:] for acts in recording.values()], dim=1\n",
    "    )\n",
    "    print(resid_stream.shape)\n",
    "\n",
    "    mask_not = (response[:, :-1] == token_open) & (response[:, 1:] == token_not)\n",
    "    mask_this = (response[:, :-1] == token_open) & (response[:, 1:] == token_this)\n",
    "    batch_idx_not, timesteps_not = torch.where(mask_not)\n",
    "    batch_idx_this, timesteps_this = torch.where(mask_this)\n",
    "\n",
    "    batch_idx_not = batch_idx_not\n",
    "    batch_idx_this = batch_idx_this\n",
    "\n",
    "    overlap_batches = torch.tensor(\n",
    "        sorted(\n",
    "            list(set(batch_idx_not.tolist()).intersection(set(batch_idx_this.tolist())))\n",
    "        )\n",
    "    ).cuda()\n",
    "    batch_mask_not = torch.isin(batch_idx_not, overlap_batches)\n",
    "    batch_mask_this = torch.isin(batch_idx_this, overlap_batches)\n",
    "\n",
    "    # TODO: probe_timestep_offset.\n",
    "    filtered_timesteps_not = {\n",
    "        b_idx: timesteps_not[(batch_idx_not == b_idx)]\n",
    "        for b_idx in overlap_batches.tolist()\n",
    "    }\n",
    "    filtered_timesteps_this = {\n",
    "        b_idx: timesteps_this[(batch_idx_this == b_idx)]\n",
    "        for b_idx in overlap_batches.tolist()\n",
    "    }\n",
    "\n",
    "    for b_idx in filtered_timesteps_not.keys():\n",
    "        _not_timesteps = filtered_timesteps_not[b_idx].tolist()\n",
    "        not_acts.append(\n",
    "            activations[\n",
    "                b_idx,\n",
    "                :,\n",
    "                _not_timesteps,\n",
    "            ].cpu()\n",
    "        )\n",
    "        _this_timesteps = filtered_timesteps_this[b_idx].tolist()\n",
    "        this_acts.append(\n",
    "            activations[\n",
    "                b_idx,\n",
    "                :,\n",
    "                _this_timesteps,\n",
    "            ].cpu()\n",
    "        )\n",
    "\n",
    "not_acts = torch.cat(not_acts, dim=1)\n",
    "this_acts = torch.cat(this_acts, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d9a2e634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 11008])\n",
      "torch.Size([12, 2048, 11008])\n",
      "Layer 24 Index 10695\n",
      "['ofil', 'ilen', '的好', 'illes', ' Toro', 'igans', 'inoa', 'halten', 'odo', 'elda']\n",
      "Layer 24 Index 1612\n",
      "['蛸', 'breaking', '丕', 'lá', 'tí', '(spec', 'ece', 'ót', '-spec', 'break']\n",
      "Layer 24 Index 1689\n",
      "['iest', '最受欢迎', '正常使用', '也正是', '喷', ' implicit', '妲', '最基本', ' MOST', '前台']\n",
      "Layer 24 Index 9559\n",
      "['###', '(es', ' ###', 'InSection', 'ighth', '字号', '不负', '_cou', '남', '�']\n",
      "Layer 24 Index 3584\n",
      "['后来', '正式', ' finally', 'finally', '到来', '来了', '实际', 'になると', '日正式', '实质']\n",
      "Layer 24 Index 3437\n",
      "['适', ' exactly', '也正是', ' precisely', 'needed', '恰好', '刚好', '正是', ' needed', '正是因为']\n",
      "Layer 24 Index 9376\n",
      "[' henne', 'ѣ', ' клуб', 'iamo', ' Cruiser', ' turnovers', ' WaitForSeconds', 'نصوص', '瞭解', 'preced']\n",
      "Layer 24 Index 2558\n",
      "[' Auto', 'Auto', ' })(', 'apolis', ' immunity', '识别', ' Soph', '�', 'auto', '&id']\n",
      "Layer 24 Index 5259\n",
      "['红线', \"(',')\\n\", '.Companion', 'getQuery', 'rim', \" '~\", '怼', '홈', '聋', ' humour']\n",
      "Layer 24 Index 7990\n",
      "['peater', ' Photographer', ' esk', 'ADC', '拍', '-max', ' buffering', 'ADR', 'commended', '洽']\n",
      "Layer 25 Index 1124\n",
      "['ELY', '怫', 'yes', ' Awesome', 'itchen', '没错', 'etur', '即时发生', 'ños', 'emade']\n",
      "Layer 25 Index 9150\n",
      "['Ace', ' smoother', ' Ace', 'ace', 'ugo', ' ACE', ' Ac', 'anse', 'w', ' wes']\n",
      "Layer 25 Index 5015\n",
      "['时不', ' Red', ' Values', 'Ph', '<![', 'ModelError', ' Ph', 'pong', '叭', 'unden']\n",
      "Layer 25 Index 7613\n",
      "['\":\"\"', ' BCE', '*/\\n\\n', ' *\\\\', ' Fletcher', '//**\\n', 'IllegalAccessException', '.*/\\n', '}*/\\n\\n', '汴']\n",
      "Layer 25 Index 2435\n",
      "[' HAND', 'sher', 'rlen', 'CLS', '着手', 'trys', '(@(', 'alla', 'ILA', 'iza']\n",
      "Layer 25 Index 432\n",
      "['let', '化', 'Convertible', 'ar', 'loon', '门', 'ells', '`', 'izar', ' GOODMAN']\n",
      "Layer 25 Index 3774\n",
      "['.\\n\\n\\n\\n', '.\"\\n\\n\\n', '.\"\\n\\n\\n\\n', ' .\\n\\n\\n\\n', '.\\n\\n\\n', ').\\n\\n\\n\\n', '.)\\n\\n', '.\\n\\n\\n\\n\\n\\n', '也不例外', '.)\\n\\n\\n\\n']\n",
      "Layer 25 Index 3170\n",
      "['##\\n\\n', 'plx', ' %\\n\\n', '自在', ':numel', ' her', 'ogle', 'otre', '两者', '']\n",
      "Layer 25 Index 833\n",
      "['！」', 'rather', ' rather', 'ighting', '.RIGHT', '？」', '取', ' Therefore', 'omet', '故']\n",
      "Layer 25 Index 1688\n",
      "[' OK', ' Brilliant', 'edList', 'okay', '好消息', ' ok', ' nice', '的优点', '敬业', 'rike']\n",
      "Layer 26 Index 6475\n",
      "['倒是', '不失', '适度', 'successful', '.success', '却是', ' successful', '没事', '完好', '还不错']\n",
      "Layer 26 Index 3665\n",
      "['урс', 'swick', '然而', 'ulton', '最新', '�', '半个', 'iox', '然', '但是']\n",
      "Layer 26 Index 6117\n",
      "[\".'\\n\\n\", '.)\\n\\n', '!).\\n\\n', '---\\n\\n', '.\")\\n\\n', '.).\\n\\n', '.\"\\n\\n', '.\"\\n\\n\\n', '!\"\\n\\n', '-----\\n\\n']\n",
      "Layer 26 Index 4048\n",
      "[' (', '(', '（', ' (\\n', '(\\n', '(\\\\', ' (_,', '(D', ' ()\\n', ' （']\n",
      "Layer 26 Index 3932\n",
      "[' Learned', 'Drop', 'drop', ' Learning', 'eer', ' chant', ' Cheat', 'icht', 'otope', ' Drop']\n",
      "Layer 26 Index 3108\n",
      "['edException', '不仅是', '不仅仅', '又是', ' właśnie', '另外一个', '不仅', '的背后', ' именно', '不但']\n",
      "Layer 26 Index 514\n",
      "['\"<?', '沔', \".');\\n\\n\", ' #\\n\\n', '.’\\n\\n', '’.\\n\\n', ' /\\n\\n', 'Disposition', '.).\\n\\n', '.Magenta']\n",
      "Layer 26 Index 4947\n",
      "[' plenty', '少不了', '不失', ' abundant', 'need', ' need', ' thousands', '⊇', 'CLU', '缺']\n",
      "Layer 26 Index 3500\n",
      "['\".', '}.', \"'.\", '\".\\n\\n', '`.', '].', '().', '.\").', '。', '\"].']\n",
      "Layer 26 Index 7026\n",
      "['金山', 'egov', 'TAB', 'hof', 'wel', '不小的', ' PURPOSE', '森', ' instruction', '相']\n",
      "Layer 27 Index 4114\n",
      "['oux', 'antas', 'hook', 'ectl', 'INTR', 'INGTON', 'PEND', ' Blonde', 'tee', 'mb']\n",
      "Layer 27 Index 10752\n",
      "['(unique', ' Column', '(bar', '⾦', ' esp', 'ufen', 'éric', 'ani', 'uft', ' Cruc']\n",
      "Layer 27 Index 3870\n",
      "['力还是', '偻', '|{\\n', 'oling', 'кри', '.TRUE', '.must', 'moid', '_GRANTED', 'weetalert']\n",
      "Layer 27 Index 5220\n",
      "['同一', '.same', '在同一', '相同', 'same', ' same', 'Same', '同期', '相近', '相似']\n",
      "Layer 27 Index 3307\n",
      "['撑', 'isms', ' arms', ' picker', 'izard', '蘧', '鹣', '嗣', '��', 'ян']\n",
      "Layer 27 Index 7106\n",
      "['蓼', ' cán', 'REA', 'PEAR', 'ENCES', 'rí', 'LC', ' provid', 'isations', 'Frameworks']\n",
      "Layer 27 Index 10388\n",
      "[' mirac', '乐观', '安然', ' Relief', '幸', '.isSuccess', '.SUCCESS', ' favorable', '优点', '顺利']\n",
      "Layer 27 Index 9186\n",
      "[' final', ' Final', 'final', ' finally', '最终', 'Final', ' FINAL', ' finalize', '\\tfinal', '(final']\n",
      "Layer 27 Index 1510\n",
      "['.drawImage', '庭', 'esper', '底', ' stop', ' tasar', ' illegally', ' bottom', 'pus', 'mak']\n",
      "Layer 27 Index 3193\n",
      "['称赞', ' nice', '欣喜', ' paradise', '美丽', '美妙', '美感', '赞美', ' praise', '尊重']\n",
      "Layer 28 Index 2836\n",
      "[' pooling', ' pooled', ' rac', '[char', 'WM', 'rik', 'ible', '而是', '辞职', '.TRUE']\n",
      "Layer 28 Index 945\n",
      "['合适', '符合', ' suitable', '合适的', '最合适', '适合', 'fits', '符合条件', '最适合', '所需要的']\n",
      "Layer 28 Index 7048\n",
      "[' equival', ' equivalent', ' Equivalent', '-equiv', ' equivalents', '际', '拍', 'Equivalent', '_equiv', ' equiv']\n",
      "Layer 28 Index 186\n",
      "['尼斯', '(Get', '萩', '/ip', 'Isl', '友', ' america', 'hort', '.GetText', ',...']\n",
      "Layer 28 Index 3835\n",
      "['atory', '裔', 'enschaft', '-ce', '/native', '+f', 'endant', '/of', '-even', '讧']\n",
      "Layer 28 Index 7094\n",
      "[' decom', '分解', ' express', ' decomposition', ' expressing', ' Express', ' Decom', 'Express', 'express', ' expresses']\n",
      "Layer 28 Index 6939\n",
      "['顺畅', '顺利', ' smoothly', '完美', '良好', '完好', '顺', '完美的', '順', ' smooth']\n",
      "Layer 28 Index 307\n",
      "['PYTHON', ' OTHERWISE', ' delet', '’T', 'ensions', 'ина', ' myself', 'ncy', ' PLAY', 'anden']\n",
      "Layer 28 Index 3384\n",
      "['混', '组织', 'izin', '\"\":', 'SHIP', '}{\\n', ' eps', '就说', 'ize', ']._']\n",
      "Layer 28 Index 3472\n",
      "['ific', 'ств', 'ist', '-frame', 'yl', 'pt', 'cial', 'lab', 'osph', 'gro']\n",
      "Layer 29 Index 5932\n",
      "['花朵', 'ilos', '殛', '纹', '(frames', 'rays', '-rays', ' lamps', '(default', '备注']\n",
      "Layer 29 Index 7140\n",
      "['!', '！', '!\\n', ' !', '!!', '!\\n\\n', '!”', '!\\\\', '!(', '!\"']\n",
      "Layer 29 Index 4028\n",
      "['|{\\n', '必', 'ött', 'unque', '.boolean', '.Misc', 'INCT', 'esz', 'essel', '必备']\n",
      "Layer 29 Index 9894\n",
      "[')\\n', ')\\n\\n', ')', ').', '):', ').\\n', '),', '):\\n', '?)', '?)\\n']\n",
      "Layer 29 Index 9569\n",
      "['\\\\\\n', '.Builder', 'ør', '葵', ' Carp', ' Shields', '贻', 'BoundingBox', ' erfolgreich', 'ож']\n",
      "Layer 29 Index 1750\n",
      "['lico', 'ployment', '了一遍', ' Booster', '敞', '[++', ' Clarkson', 'ensch', 'ök', ' booster']\n",
      "Layer 29 Index 757\n",
      "['.asm', ' Fil', '.Go', \"',(\", ' sequ', '独立', ' Braz', 'UPI', '獨立', \"':[\"]\n",
      "Layer 29 Index 917\n",
      "[\"\\\\'\", '秉', '昭', ' yab', 'Ī', ' sl', 'Sl', ' Fran', '\\\\xd', \"=\\\\'\"]\n",
      "Layer 29 Index 10862\n",
      "['älle', 'cid', '干事', '想过', 'PageIndex', 'ahas', '的灵魂', ':result', 'HeaderCode', 'tré']\n",
      "Layer 29 Index 2570\n",
      "['摅', 'auses', 'ERGY', 'deen', 'DY', '_DI', ' protein', 'Td', '��', 'edBy']\n",
      "Layer 30 Index 8170\n",
      "['mojom', '（笑', 'rax', \"'url\", '❮', 'createUrl', 'gatsby', '国情', '@Configuration', '_HOME']\n",
      "Layer 30 Index 2129\n",
      "['IDE', 'BOSE', 'vin', '触发', ' Aires', '峙', 'omy', '-comm', '经纬', ' reluct']\n",
      "Layer 30 Index 3179\n",
      "[' Import', \".',\\n\", ' import', '\\timport', '.\",\\r\\n', '进口', \".',\\r\\n\", '.\",', \".',\", '.\",\\n']\n",
      "Layer 30 Index 1983\n",
      "[' Downs', 'لي', '各行', '岁时', 'rist', '早晚', 'it', 'andles', '水中', 'lst']\n",
      "Layer 30 Index 3989\n",
      "['...\\n\\n\\n', '…\\n\\n\\n', '--\\n\\n', ' --\\n\\n', '._\\n\\n', '...\\n\\n', '—\\n\\n', '…\\n\\n', '...\"\\n\\n', '......\\n\\n']\n",
      "Layer 30 Index 2992\n",
      "['��', 'resse', ')item', 'SCR', 'osti', ')size', '>>>(', ')V', ';)', '。']\n",
      "Layer 30 Index 9414\n",
      "[' \\xad', '\\xadtion', '\\xadt', '\\xa0', '\\xad', ' “', 'Â', '制订', ' (“', '\\xads']\n",
      "Layer 30 Index 10967\n",
      "['的一种', '的一', '的一些', '的好', '的心', '的一部分', '的情', '的一大', '的一个', 'ima']\n",
      "Layer 30 Index 3398\n",
      "[' Spicer', 'dden', 'excel', '芍', 'rove', '缓', 'bc', '动物园', '炀', '否則']\n",
      "Layer 30 Index 724\n",
      "[' -', ' (', 'па', 'bel', '~', '/S', '/M', '/B', '---', '-S']\n",
      "Layer 31 Index 4851\n",
      "['CAF', 'bió', 'WithValue', 'PFN', 'isque', 'CTS', 'nda', ' المص', ' Tup', '(\"(%']\n",
      "Layer 31 Index 5700\n",
      "[' eleven', 'etter', 'enia', '3', 'ofil', '３', '三家', ' three', 'cret', '穆']\n",
      "Layer 31 Index 9889\n",
      "[' exactly', ' exact', ' Exactly', ' precisely', 'Exactly', ' Exact', 'exact', 'Exact', '_exact', ' precise']\n",
      "Layer 31 Index 186\n",
      "['，', '，“', '。', '，在', '，请', '。<', '，《', '，并', '；', '。，']\n",
      "Layer 31 Index 8027\n",
      "[']()\\n', '{}\\n', ':)\\n', '!\\n', \"!')\\n\", ')!\\n', '!!\\n', '(\"/\")\\n', '!\")\\n', '!\")\\r\\n']\n",
      "Layer 31 Index 3620\n",
      "[' التط', 'ANGE', '局长', ' rad', 'Po', 'Brad', '.gs', 'ako', ' Mik', 'BK']\n",
      "Layer 31 Index 5412\n",
      "['APPER', 'robat', 'curacy', ' unless', '为止', 'ecd', ' while', 'eec', '都要', '为准']\n",
      "Layer 31 Index 1071\n",
      "[' */\\n\\n\\n\\n', '...\\n\\n\\n\\n\\n\\n', '?\"\\n\\n\\n\\n', '!\\n\\n\\n\\n\\n\\n', '!\\n\\n\\n\\n', '...\\n\\n\\n\\n', ' {\\n\\n\\n\\n', ' —\\n\\n', '…\\n\\n\\n\\n', '\".\\n\\n\\n\\n']\n",
      "Layer 31 Index 4898\n",
      "['هى', ' NEC', ' Bacon', '陇', 'età', 'ñas', '甯', ' Nes', 'acos', 'croft']\n",
      "Layer 31 Index 1102\n",
      "[' ``', ' \\\\\"', '。「', '、「', '(`', '\\\\\"', '「', '\\\\n', ' 「', ':`']\n",
      "Layer 32 Index 3934\n",
      "[' köln', ' münchen', ' nuru', ' görmek', 'awks', 'iture', ' limburg', 'nah', 'AGMA', 'moid']\n",
      "Layer 32 Index 1094\n",
      "['[,]', '[method', ' {?', '[attr', 'ibel', '.SuspendLayout', '[Test', '[event', '[H', '[it']\n",
      "Layer 32 Index 5298\n",
      "['(\"<?', 'dbl', 'ources', 'cxx', '($(\".', 'dif', '_prec', '[/', 'plen', ' Grü']\n",
      "Layer 32 Index 1105\n",
      "[\"([('\", '정', '([(', ' props', '://\"', 'thr', '\\\\.', 'etur', ' La', ')[-']\n",
      "Layer 32 Index 8253\n",
      "[' khỏ', ' Inhal', ' grop', 'hait', ' selber', ' turnovers', ' ogóln', ' brib', ' eskort', ' halk']\n",
      "Layer 32 Index 1250\n",
      "[' ...\\n', '…\\n', ' …\\n\\n', '...\\n', ' ...\\n\\n', '…\\n\\n', ' ...\\n\\n\\n\\n', '\\n', '...\\n\\n', '…\\n\\n\\n']\n",
      "Layer 32 Index 5095\n",
      "['ildo', ' Lage', '&view', '意见建议', '\"\\\\\\n', 'rieg', 'Attrs', '打出', '屆', ' Pics']\n",
      "Layer 32 Index 9671\n",
      "['熟', 'ep', ' push', 'A', ' stagger', '.UN', 'elp', ' ##', 'Artist', '血']\n",
      "Layer 32 Index 6397\n",
      "['-With', 'Intialized', ' Of', ' With', '-To', ' For', '_Of', ' definit', '-The', 'Of']\n",
      "Layer 32 Index 7038\n",
      "['\":\\n', '\"\\r\\n', '\":\\r\\n', '.\"\\r\\n', ':\"\\n', '()\"\\n', '”。\\n\\n', '\"\\r\\n\\r\\n', '\"\\n\\n', '\"\\n']\n",
      "Layer 33 Index 6674\n",
      "[' (>', ' fired', 'iska', '(', ' firing', '--------------------------------------------------------------------------\\n', 'ordes', ' (“', ' }>', ' (@']\n",
      "Layer 33 Index 3509\n",
      "['ivery', 'hot', 'hos', 'sst', 'elic', ' AppComponent', 'atoire', '浆', '.nodeType', 'Js']\n",
      "Layer 33 Index 7504\n",
      "['苾', '{}\\\\', 'ceph', '#[', '***\\n', '&a', '\\\\/\\\\/', '//\\n\\n', ':nil', '<hr']\n",
      "Layer 33 Index 8791\n",
      "['vel', 'kw', 'vely', 'w', 'cht', 'm', 'wd', 'wr', 'KIT', 'wy']\n",
      "Layer 33 Index 1633\n",
      "['槎', 'prise', ' Madden', 'иров', 'ener', 'irates', 'pike', 'graph', ' ling', 'datagrid']\n",
      "Layer 33 Index 8368\n",
      "[' FUCK', ' Fucked', ' queued', ' pissed', ' fucked', 'LICENSE', ' simplement', '庞大的', '万余', ' darn']\n",
      "Layer 33 Index 10621\n",
      "['>,', ' [],', '”,', '】,', '**,', ' />,', '\",', '%,', '],', '?,']\n",
      "Layer 33 Index 10604\n",
      "[' \\xa0 \\xa0', 'ffiti', 'ormap', ' \\xa0', '笑笑', 'igar', '螨', 'Smarty', '}', ' clinically']\n",
      "Layer 33 Index 7906\n",
      "['(proc', '伐', 'proc', 'inta', 'jec', 'iec', 'oud', 'PROC', 'ć', ' Jacqu']\n",
      "Layer 33 Index 1831\n",
      "[' \\u200b\\u200b', ' imm', 'いる', 'sam', 'atted', ' tangent', 'antar', 'こと', 'ữa', 'atics']\n",
      "Layer 34 Index 10874\n",
      "['\"f', ').(', '\"h', \" '\", ' ‘', ')”', ')b', ')t', ' \"', ' ,\"']\n",
      "Layer 34 Index 9848\n",
      "['能满足', '众所周', '招商引', ' eskort', '趿', '主营业', 'تقار', 'температур', ' Günc', 'IÓN']\n",
      "Layer 34 Index 10298\n",
      "['，', '，在', '，《', '，则', '，并', '，请', '，默认', '：\"', '،', '，“']\n",
      "Layer 34 Index 8710\n",
      "['%c', '–\\n\\n', '****\\n', 'NotNil', '***\\n', '...\";\\n', 'Assignable', '):\\\\', '?\";\\n', ' HttpNotFound']\n",
      "Layer 34 Index 10605\n",
      "[' Rubin', 'oste', 'anza', 'あげ', 'castHit', ' tslint', 'chaft', 'ype', 'ignored', 'quo']\n",
      "Layer 34 Index 1979\n",
      "[')\"\\n\\n', ')\"\\n', ')<', \")'\", ')\\n\\n', '):', ')\"', ')\\\\', ')\";\\n', ')\\n']\n",
      "Layer 34 Index 7358\n",
      "['_GRANTED', '降', 'ourse', '.water', 'water', '谤', '缑', '下乡', '森林', '.go']\n",
      "Layer 34 Index 7011\n",
      "['.\\r\\n', '.\\n', '.\\\\', '.\\r\\n\\r\\n', '.\"\\r\\n', '.\",\\r\\n', '().\\n', '.\\n\\n', \".',\\n\", '.\",\\n']\n",
      "Layer 34 Index 2184\n",
      "['即时发生', ' addCriterion', '取得以及', ' дело', 'お互', 'rust', '▿', 'أوضاع', '重中之重', ' CAUSED']\n",
      "Layer 34 Index 2243\n",
      "['–', '…”', '—', '”—', ' —', ' –', '…', '——', '–and', '‐']\n",
      "Layer 35 Index 6751\n",
      "['}->', '\\\\:', '},\"', '],&', '}[', '}};\\n', ']\\\\\\\\', '},{\"', '}\\\\\\\\', \"]='\"]\n",
      "Layer 35 Index 1613\n",
      "['}', '}}', '\\u200b', '</', '}\\\\\\\\', '}}}', \"']\", '】', ')||', '?']\n",
      "Layer 35 Index 7165\n",
      "['1', 'italize', 'inate', 'opleft', ' Nug', '利物', 'ôm', ' flown', 'CTOR', 'ouse']\n",
      "Layer 35 Index 3403\n",
      "[' herself', ' anybody', '此种', '的那种', '那种', ' WHICH', ' everytime', '来进行', ' ourselves', ' themselves']\n",
      "Layer 35 Index 3294\n",
      "['.setHorizontal', '.setTo', '(update', '.setFill', '=add', '(return', 'modifiable', '乗', '.setFocus', ' Turn']\n",
      "Layer 35 Index 6312\n",
      "[' ', '-', '\\u200b', '_', '1', ',', '...', '2', '.', 'i']\n",
      "Layer 35 Index 4376\n",
      "[' ', ' �', '\\u200b', '�', '�', '-', '(', '_', '1', ' (']\n",
      "Layer 35 Index 8443\n",
      "[' conformity', ' jednocześnie', ' karşısında', ' interchange', 'urally', ' döneminde', ' pozostał', ' znalazł', 'くなりました', '_iterator']\n",
      "Layer 35 Index 10490\n",
      "['.cn', ' Advertisement', 'owi', 'urg', 'și', ' tap', ' guy', '目', '/=', 'uler']\n",
      "Layer 35 Index 8081\n",
      "['__', ' \\\\', '*****', '-->', '\\\\_', '\"]/', '}}}', \"']\", '_____', '\")+']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "_not_acts = not_acts.clone()\n",
    "_this_acts = this_acts.clone()\n",
    "\n",
    "# [_layers, d_mlp]\n",
    "_not_acts = _not_acts.mean(dim=1).cuda()\n",
    "_this_acts = _this_acts.mean(dim=1).cuda()\n",
    "\n",
    "_value_vecs = value_vecs[mlp_layers]\n",
    "\n",
    "print(_not_acts.shape)\n",
    "print(_value_vecs.shape)\n",
    "\n",
    "# [layers, d_model, d_mlp]\n",
    "neg_scaled_value_vecs = _not_acts.unsqueeze(1) * _value_vecs\n",
    "pos_scaled_value_vecs = _this_acts.unsqueeze(1) * _value_vecs\n",
    "\n",
    "# [layers, d_mlp]\n",
    "dot_prods = einsum(\n",
    "    \"layers d_model d_mlp, layers d_model -> layers d_mlp\",\n",
    "    pos_scaled_value_vecs,\n",
    "    probe_model[mlp_layers, :, 1],\n",
    ")\n",
    "\n",
    "for layer_idx in range(dot_prods.shape[0]):\n",
    "    top_idxs = dot_prods[layer_idx].topk(k=10).indices\n",
    "\n",
    "    curr_layer = mlp_layers[layer_idx]\n",
    "    for _idx in top_idxs.tolist():\n",
    "        print(f\"Layer {curr_layer} Index {_idx}\")\n",
    "        curr_value_vecs = actor.model.layers[curr_layer].mlp.down_proj.weight[:, _idx]\n",
    "\n",
    "        print(unembed_text(curr_value_vecs, actor.lm_head.weight, actor.tokenizer, k=10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
